# LlamaApp ユーザーマニュアル

**バージョン**: 1.0
**最終更新**: 2025-11-15
**対象**: 一般ユーザー向け使い方ガイド

---

## 📑 目次

1. [はじめに](#1-はじめに)
2. [インストールと初回セットアップ](#2-インストールと初回セットアップ)
3. [基本的な使い方](#3-基本的な使い方)
4. [モデル管理](#4-モデル管理)
5. [RAG機能（Web Knowledge）](#5-rag機能web-knowledge)
6. [Agent機能（ファイル操作）](#6-agent機能ファイル操作)
7. [設定](#7-設定)
8. [トラブルシューティング](#8-トラブルシューティング)
9. [FAQ](#9-faq)

---

## 1. はじめに

### LlamaAppとは？

LlamaAppは、あなたのMac上で完全にプライベートに動作するAIチャットアプリケーションです。すべてのデータと処理はローカルで完結し、インターネットにデータを送信しません。

### 主な特徴

✅ **完全プライベート** - すべてローカルで動作、外部送信なし
✅ **ChatGPT風のUI** - 使いやすいストリーミングチャット画面
✅ **豊富なモデル** - 13種類のプリセットモデルから選択可能
✅ **RAG機能** - ウェブページを読み込んで知識として活用
✅ **Agent機能** - ファイルの読み書き・検索をAIが自動実行
✅ **高速** - Metal GPUアクセラレーションで快適な応答速度

### 必要環境

- **OS**: macOS 13 (Ventura) 以降
- **メモリ**: 最小8GB、推奨16GB以上
- **ストレージ**: モデルごとに1-12GB（最低4GB以上の空き容量）
- **GPU**: Metal対応GPU（Apple Silicon推奨）

---

## 2. インストールと初回セットアップ

### 2.1 インストール

1. **アプリケーションのダウンロード**
   - GitHubリリースページから最新版のDMGファイルをダウンロード
   - Apple Siliconの場合: `LlamaApp-x.x.x-arm64.dmg`
   - Intel Macの場合: `LlamaApp-x.x.x-x64.dmg`

2. **インストール**
   - DMGファイルをダブルクリックして開く
   - LlamaAppアイコンをアプリケーションフォルダにドラッグ

3. **初回起動**
   - アプリケーションフォルダからLlamaAppを起動
   - 「開発元を確認できません」という警告が出た場合:
     - 右クリック → 「開く」を選択
     - 「開く」ボタンをクリック

### 2.2 最初のモデルをダウンロード

アプリを使用するには、まずAIモデルをダウンロードする必要があります。

1. **モデルストアを開く**
   - ヘッダー右上の **🏪 モデルストア** ボタンをクリック

2. **モデルを選択**
   - 初めての方には **Gemma 2 2B Instruct** (軽量・高速) がおすすめ
   - メモリに余裕がある場合は **Mistral 7B Instruct** (高性能) もおすすめ

3. **ダウンロード開始**
   - 選んだモデルの **ダウンロード** ボタンをクリック
   - プログレスバーで進捗を確認（数分〜10分程度）

4. **完了**
   - ダウンロードが完了すると、モデルドロップダウンに自動追加されます

---

## 3. 基本的な使い方

### 3.1 チャットの基本操作

1. **メッセージ入力**
   - 画面下部の入力欄にメッセージを入力
   - Enterキーで送信（Shift+Enterで改行）

2. **AIの応答を待つ**
   - メッセージ送信後、AIがリアルタイムで応答を生成
   - トークンが1つずつストリーミング表示されます

3. **応答の停止**
   - 生成中に **停止** ボタンをクリックすると、途中で応答を中断できます

### 3.2 便利な機能

#### メッセージのコピー

各メッセージの右上にある **📋 コピー** アイコンをクリックすると、内容をクリップボードにコピーできます。

#### マークダウン対応

AIの応答は自動的にマークダウンとして表示されます：

- **太字**: `**太字**` → **太字**
- **見出し**: `## 見出し` → 見出しスタイル
- **コードブロック**: バッククォート3つで囲む
- **リスト**: `-` または `1.` で箇条書き
- **リンク**: `[テキスト](URL)` → クリック可能なリンク

#### コードのシンタックスハイライト

プログラミングコードは自動的に色付けされます：

```python
def hello():
    print("Hello, World!")
```

### 3.3 チャットのヒント

**効果的な質問の仕方**

✅ **具体的に質問する**
```
良い例: 「Pythonでファイルを読み込む方法を教えて」
悪い例: 「ファイル読み込み」
```

✅ **コンテキストを提供する**
```
良い例: 「JavaScriptで配列から重複を削除したいです。ES6の方法を教えてください」
悪い例: 「配列の重複削除」
```

✅ **段階的に質問する**
```
1. まず概要を理解
2. 詳細な実装を質問
3. 特定の問題を解決
```

---

## 4. モデル管理

### 4.1 モデルストアから追加

#### 4.1.1 モデルストアを開く

ヘッダーの **🏪 モデルストア** ボタンをクリック

#### 4.1.2 プリセットモデル一覧

| カテゴリ | モデル | サイズ | メモリ | 特徴 | ライセンス |
|---------|--------|--------|--------|------|-----------|
| **超軽量** | TinyLlama 1.1B Chat | 669MB | 2GB | 超小型・超高速 | 商用可 ✅ |
| | Gemma 2 2B Instruct | 1.6GB | 3GB | Google製 | 商用可 ✅ |
| **軽量** | Llama 3.2 3B Instruct | 2.0GB | 4GB | 最新・高性能 | 非商用 |
| | Phi-3 Mini 4K | 2.2GB | 4GB | Microsoft製 | 商用可 ✅ |
| **中型** | Llama 2 7B Chat | 3.8GB | 6GB | 安定版 | 非商用 |
| | CodeLlama 7B Instruct | 3.8GB | 6GB | コード特化 | 非商用 |
| | Mistral 7B Instruct | 4.1GB | 6GB | 高性能 | 商用可 ✅ |
| | Qwen 2.5 7B Instruct | 4.3GB | 6GB | 多言語対応 | 商用可 ✅ |
| | Llama 3.1 8B Instruct | 4.9GB | 8GB | 最新・強力 | 非商用 |
| **大型** | OpenAI GPT-OSS 20B | 11.6GB | 16GB | 低レイテンシ | 商用可 ✅ |

#### 4.1.3 ライセンスフィルター

- **すべて表示**: すべてのモデルを表示
- **商用可のみ**: ビジネス利用可能なモデルのみ表示

#### 4.1.4 ダウンロード手順

1. 好みのモデルを選択
2. **ライセンス** と **メモリ要件** を確認
3. **ダウンロード** ボタンをクリック
4. プログレスバーで進捗確認
   - ダウンロード速度と残り時間が表示されます
5. 完了後、自動的にモデル一覧に追加

### 4.2 手動でモデルを追加

HuggingFaceなどから独自のGGUFモデルをダウンロードした場合：

1. ヘッダーの **+ モデル追加** ボタンをクリック
2. GGUFファイルを選択
3. 自動的にインポートされます

### 4.3 モデルの切り替え

1. ヘッダーのモデルドロップダウンをクリック
2. 使用したいモデルを選択
3. モデルのロード完了を待つ（20-40秒）
4. チャット開始！

**注意**: モデル切り替え時は現在の会話がリセットされます。

### 4.4 モデルの削除

1. **🏪 モデルストア** を開く
2. インストール済みモデルの **🗑️ 削除** ボタンをクリック
3. 確認ダイアログで **OK** をクリック
4. モデルファイルが削除されます

**削除されるファイルの場所**:
```
~/Library/Application Support/Llamaapp/models/
```

---

## 5. RAG機能（Web Knowledge）

### 5.1 RAGとは？

RAG（Retrieval Augmented Generation）は、ウェブページの内容をAIのコンテキストとして活用できる機能です。インデックス化したページから関連情報を自動検索し、より正確な回答を生成します。

**RAGの仕組み**
```
質問 → 検索 → コンテキスト生成 → LLM推論 → 回答
```

### 5.2 RAGの使い方

#### 5.2.1 RAGパネルを開く

ヘッダーの **🔍 RAG** ボタンをクリック

#### 5.2.2 ウェブページを追加

1. **URLを入力**
   - 入力欄にウェブページのURLを貼り付け
   - 例: `https://react.dev/reference/react/useState`

2. **追加ボタンをクリック**
   - URL一覧に追加されます

#### 5.2.3 インデックス化

1. **インデックス化ボタンをクリック**
   - 追加したURLの **インデックス化** ボタンをクリック

2. **進捗確認**
   - プログレスバーで進捗を確認：
     - **fetching**: ページ取得中
     - **chunking**: テキスト分割中（500文字ごと）
     - **indexing**: データベース保存中
   - 完了すると「✅ 完了」ステータスに変わります

#### 5.2.4 RAGを有効化

パネル上部の **RAG有効化** トグルをONにする

#### 5.2.5 チャットで使用

RAGが有効な状態で質問すると：
1. インデックスから関連チャンクを検索（上位3件）
2. 検索結果をプロンプトに追加
3. LLMがコンテキストを参照して回答

### 5.3 実用例

#### 例1: 技術ドキュメントの活用

```
1. React公式ドキュメントをインデックス化
   https://react.dev/reference/react/useState

2. 質問する
   「useStateの第2引数について詳しく教えて」

3. 結果
   → 公式ドキュメントの内容を参照した正確な回答
```

#### 例2: 複数記事の横断検索

```
1. 関連記事を複数インデックス化
   https://example.com/article1
   https://example.com/article2
   https://example.com/article3

2. 質問する
   「これらの記事の共通点は何？」

3. 結果
   → 複数記事から関連情報を抽出して要約
```

#### 例3: 最新ニュースの活用

```
1. ニュース記事をインデックス化
   https://news.example.com/latest-ai-news

2. 質問する
   「最新のAI技術トレンドは？」

3. 結果
   → 記事の内容を基にした最新情報の回答
```

### 5.4 制限事項

⚠️ **対応形式**: HTMLのみ（PDF、動画等は非対応）
⚠️ **JavaScript**: 静的HTML取得のみ（SPAは内容取得できない場合あり）
⚠️ **認証**: ログインが必要なページは取得不可
⚠️ **検索方式**: 簡易的なキーワードマッチング（ベクトル検索ではない）

---

## 6. Agent機能（ファイル操作）

### 6.1 Agent機能とは？

Agent機能は、AIがあなたの指示に従ってファイルの読み書きや検索を自動実行する機能です。

**できること**
- ファイルの読み取り
- ディレクトリ一覧の表示
- ファイル検索
- ログ分析
- JSON/CSVデータの分析
- ファイルの作成・編集・削除（確認ダイアログ付き）

### 6.2 基本的な使い方

通常のチャットで、ファイル操作の指示を出すだけです：

```
例1: 「~/Documents/test.txt の内容を読んで要約して」
→ AIがファイルを読み取って要約

例2: 「~/Desktop のファイル一覧を表示して」
→ AIがディレクトリ一覧を取得

例3: 「~/Documents の中で .log ファイルを検索して」
→ AIがファイルを検索
```

### 6.3 Agent実行中の表示

Agent機能が実行されると：

1. **実行インジケーター表示**
   - 画面右下に実行中のツール情報が表示
   - 例: 「📄 Reading file... ~/Documents/test.txt」

2. **プログレスバー**
   - 処理の進捗を視覚的に表示

3. **完了通知**
   - ✅ マークと共に完了を通知

### 6.4 セキュリティと許可設定

#### 6.4.1 許可ディレクトリ

デフォルトで以下のディレクトリのみアクセス可能：
- `~/Documents`
- `~/Desktop`
- `~/Downloads`

**変更方法**:
設定パネルから許可ディレクトリを追加・削除できます（開発中）

#### 6.4.2 ブロックされるディレクトリ

セキュリティのため、以下には常にアクセスできません：
- `/System` - システムディレクトリ
- `/private` - プライベートシステム領域
- `~/.ssh` - SSH鍵
- `~/Library/Keychains` - キーチェーン

#### 6.4.3 センシティブファイルの保護

以下のファイルは自動的にブロックされます：
- `.env` - 環境変数
- `credentials` を含むファイル
- `password` を含むファイル
- `.key`, `.pem` - 秘密鍵ファイル
- `id_rsa` - SSH秘密鍵

### 6.5 ファイル読み取りの例

#### 例1: テキストファイルの要約

```
あなた: 「~/Documents/report.txt を読んで要約して」

Agent:
1. read_file(path: "~/Documents/report.txt")
2. ファイル内容を取得（3,245文字、52行）
3. LLMが内容を要約

結果: 「このレポートは...」（要約が表示される）
```

#### 例2: ディレクトリの分析

```
あなた: 「~/Documents のファイル一覧を表示して、サイズの大きい順に並べて」

Agent:
1. list_directory(path: "~/Documents")
2. ファイル情報を取得
3. LLMがサイズ順にソート

結果: ファイル一覧が表形式で表示
```

### 6.6 ファイル書き込みの例

**注意**: 書き込み操作には常に確認ダイアログが表示されます

#### 例1: ファイル作成

```
あなた: 「~/Desktop/memo.txt に "Hello World" を書いて」

Agent:
1. 確認ダイアログ表示
   - ツール: 📝 Write File
   - パス: ~/Desktop/memo.txt
   - サイズ: 11 bytes
   - プレビュー: "Hello World"

2. あなたが「Confirm」をクリック

3. write_file(path: "~/Desktop/memo.txt", content: "Hello World")

4. 完了通知: ✅ ファイルが作成されました
```

#### 例2: ファイル削除

```
あなた: 「~/Desktop/old_file.txt を削除して」

Agent:
1. 確認ダイアログ表示（危険度: 高）
   - ⚠️ This is a potentially destructive operation
   - ツール: 🗑️ Delete File
   - パス: ~/Desktop/old_file.txt
   - 注意: ファイルはゴミ箱に移動されます

2. あなたが「Confirm」をクリック

3. delete_file(path: "~/Desktop/old_file.txt")

4. 完了通知: ✅ ファイルをゴミ箱に移動しました
```

### 6.7 システム管理とデータ処理

#### ディスク使用量の確認

```
あなた: 「~/Documents のディスク使用量を教えて」

Agent:
1. get_disk_usage(path: "~/Documents")
2. 各ファイル・フォルダのサイズを取得
3. サイズ順にソート（上位20件）

結果: ディスク使用量の一覧が表形式で表示
```

#### ログファイル分析

```
あなた: 「~/Logs/app.log でエラーを検索して」

Agent:
1. analyze_logs(path: "~/Logs/app.log", pattern: "error")
2. エラー行を抽出
3. 警告行も抽出

結果:
- 総行数: 1,245行
- エラー: 23件
- 警告: 45件
- エラー行の詳細リスト
```

#### JSON/CSVデータ分析

```
あなた: 「~/Documents/data.json の構造を教えて」

Agent:
1. analyze_json(path: "~/Documents/data.json")
2. JSONの型・構造を解析
3. サンプルデータを取得

結果: JSON構造の説明と主要フィールドの一覧
```

### 6.8 実行履歴の確認

すべてのAgent実行は履歴に記録されます：

1. **履歴サイドバーを開く**（開発中）
   - ヘッダーの履歴アイコンをクリック

2. **履歴の内容**
   - 実行時刻
   - ツール名
   - 対象ファイル/ディレクトリ
   - 成功/失敗ステータス

3. **履歴のクリア**
   - 「Clear」ボタンで履歴を削除

---

## 7. 設定

### 7.1 設定パネルを開く

ヘッダーの **⚙️ 設定** ボタンをクリック

### 7.2 システムプロンプト

AIの基本的な振る舞いをカスタマイズできます。

**デフォルトのプロンプト**:
```
You are a helpful AI assistant.
```

**カスタマイズ例**:
```
あなたは親切な日本語アシスタントです。
以下のルールに従ってください：
- 常に丁寧語を使う
- コードは詳しく説明する
- 不明な点は明確に伝える
```

**変更方法**:
1. システムプロンプト入力欄をクリック
2. 好みのプロンプトを入力
3. 「保存」ボタンをクリック

### 7.3 温度（Temperature）

AIの創造性を調整します。

- **0.0**: 決定論的（常に同じ回答）
- **0.7**: バランス型（推奨）
- **1.0**: 創造的（多様な回答）
- **1.5**: 非常に創造的（予測不能）

**おすすめ設定**:
- コード生成: 0.3-0.5
- 一般的な会話: 0.7
- 創作・ブレインストーミング: 1.0-1.2

### 7.4 最大トークン数

AIの応答の最大長を設定します。

- **256**: 短い回答（数行）
- **512**: 中程度の回答（1-2段落）
- **1024**: 長い回答（推奨）
- **2048**: 非常に長い回答（記事レベル）

**注意**: 大きな値にするとメモリ使用量が増加します。

### 7.5 Agent許可ディレクトリ（開発中）

Agentがアクセスできるディレクトリを管理します。

1. 「ディレクトリを追加」ボタンをクリック
2. フォルダを選択
3. 一覧に追加されます

削除する場合は、各ディレクトリの「削除」ボタンをクリック。

---

## 8. トラブルシューティング

### 8.1 モデルが読み込めない

**症状**: モデル切り替え時に「読み込み失敗」エラー

**原因と対策**:

1. **メモリ不足**
   - アクティビティモニタでメモリ使用量を確認
   - より小さいモデル（Gemma 2 2BやPhi-3 Mini）に切り替え
   - 他のアプリケーションを終了

2. **ファイル破損**
   - モデルを削除して再ダウンロード
   - ダウンロード中にエラーが出た場合は再実行

3. **Metal GPU未対応**
   - システム情報でGPUを確認
   - Metal対応GPUが必要（macOS 13以降のほとんどのMac）

### 8.2 ダウンロードが失敗する

**症状**: モデルダウンロード中に中断

**原因と対策**:

1. **ネットワーク接続**
   - Wi-Fi/有線接続を確認
   - 安定した回線で再試行

2. **ディスク容量不足**
   - ストレージ容量を確認（最低10GB推奨）
   - 不要なファイルを削除

3. **ファイアウォール/VPN**
   - 一時的にファイアウォールを無効化
   - VPNを切断して再試行

### 8.3 アプリが起動しない

**症状**: LlamaAppが起動時にクラッシュ

**対策**:

1. **キャッシュクリア**（開発者向け）
   ```bash
   rm -rf ~/Library/Application\ Support/Llamaapp/
   ```
   注意: すべてのモデルと設定が削除されます

2. **再インストール**
   - アプリケーションフォルダからLlamaAppを削除
   - DMGファイルから再インストール

3. **macOSバージョン確認**
   - macOS 13 (Ventura) 以降が必要
   - 古いバージョンの場合はアップデート

### 8.4 応答が遅い

**症状**: AIの応答生成が非常に遅い

**原因と対策**:

1. **モデルサイズが大きすぎる**
   - より小さいモデルに切り替え
   - 推奨: 8GBメモリ → 2-3Bモデル、16GB → 7Bモデル

2. **Metal GPU未使用**
   - コンソールログで確認（開発者向け）
   - `ggml_metal_init: loaded kernel` が表示されるべき

3. **バックグラウンドプロセス**
   - アクティビティモニタでCPU使用率を確認
   - 他の重いアプリケーションを終了

### 8.5 Agent機能が動作しない

**症状**: 「Permission denied」エラーが出る

**原因と対策**:

1. **許可ディレクトリ外**
   - 許可されたディレクトリ内で操作
   - デフォルト: `~/Documents`, `~/Desktop`, `~/Downloads`

2. **センシティブファイル**
   - `.env`, `password`, `.key` などは保護されています
   - 別の場所にコピーしてから操作

3. **システムディレクトリ**
   - `/System`, `/private` などはブロックされています
   - ユーザーディレクトリ内で操作してください

---

## 9. FAQ

### Q1. データはどこに保存されますか？

**A**: すべてのデータはローカルに保存されます：

- **モデル**: `~/Library/Application Support/Llamaapp/models/`
- **設定**: `~/Library/Application Support/Llamaapp/config.json`
- **RAGインデックス**: `~/Library/Application Support/Llamaapp/rag.db`
- **会話履歴**: 現在は未実装（Phase 4で追加予定）

### Q2. インターネットに接続する必要はありますか？

**A**: モデルダウンロード時とRAG機能でウェブページを取得する時のみ必要です。チャット自体は完全オフラインで動作します。

### Q3. 複数の会話を保存できますか？

**A**: 現在は未実装です。Phase 4（会話履歴機能）で追加予定です。

### Q4. GPT-4と同じくらい賢いですか？

**A**: ローカルモデルは、GPT-4のような大規模クラウドモデルより性能は劣りますが、プライバシーと速度で優れています。用途に応じて使い分けてください。

**目安**:
- 軽量モデル（2-3B）: 簡単な質問、コード補完、要約
- 中型モデル（7-8B）: 複雑な質問、長文生成、データ分析
- 大型モデル（20B）: 高度な推論、詳細な説明

### Q5. 商用利用できますか？

**A**: モデルのライセンスによります。モデルストアで「商用可 ✅」マークのあるモデルは商用利用可能です。

**商用可モデルの例**:
- Mistral 7B Instruct
- Gemma 2 2B Instruct
- Phi-3 Mini
- Qwen 2.5 7B Instruct

### Q6. 日本語に対応していますか？

**A**: すべてのモデルが日本語に対応していますが、性能には差があります。

**日本語推奨モデル**:
- Qwen 2.5 7B Instruct（多言語対応が強い）
- Llama 3.1 8B Instruct（日本語も比較的良好）

### Q7. GPUが必要ですか？

**A**: Metal対応GPUがあると大幅に高速化されますが、CPUのみでも動作します（非常に遅い）。macOS 13以降のほとんどのMacはMetal対応です。

### Q8. モデルを削除してもファイルが残っています

**A**: ファイルが使用中の可能性があります：
1. LlamaAppを完全に終了
2. ファイルマネージャで手動削除: `~/Library/Application Support/Llamaapp/models/`

### Q9. RAGでPDFを読み込めますか？

**A**: 現在はHTMLのみ対応しています。PDF対応はPhase 3以降で検討中です。

**回避策**: PDFをHTMLに変換するか、テキストファイルとして保存してAgent機能で読み込む

### Q10. エラーログはどこで確認できますか？

**A**: 開発者向け機能です：
1. アプリを起動
2. メニューバー → 表示 → デベロッパーツール
3. Consoleタブでログを確認

---

## 🎓 次のステップ

LlamaAppをマスターしたら：

1. **RAGで知識ベース構築**
   - よく参照するドキュメントをインデックス化
   - 専門分野の知識を蓄積

2. **Agentで自動化**
   - 定期的なログ分析を自動化
   - データ処理パイプラインの構築

3. **カスタムシステムプロンプト**
   - 特定の用途に特化したアシスタントを作成
   - ロールプレイ、専門家モード

4. **コミュニティに参加**
   - GitHubでバグ報告・機能提案
   - 使い方のシェア

---

## 📞 サポート

- **GitHub Issues**: バグ報告・機能提案
- **ドキュメント**: README.md、AGENT_SPEC.md

---

**Happy Chatting! 🎉**
